{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42a9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "import os\n",
    "import wget\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d279429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobno</th>\n",
       "      <th>CR1_mean</th>\n",
       "      <th>CR1_min</th>\n",
       "      <th>CR1_max</th>\n",
       "      <th>CR1_std</th>\n",
       "      <th>CR1_var</th>\n",
       "      <th>ER1_mean</th>\n",
       "      <th>ER1_min</th>\n",
       "      <th>ER1_max</th>\n",
       "      <th>ER1_std</th>\n",
       "      <th>...</th>\n",
       "      <th>ST1_min</th>\n",
       "      <th>ST1_max</th>\n",
       "      <th>ST1_std</th>\n",
       "      <th>ST1_var</th>\n",
       "      <th>ST2_mean</th>\n",
       "      <th>ST2_min</th>\n",
       "      <th>ST2_max</th>\n",
       "      <th>ST2_std</th>\n",
       "      <th>ST2_var</th>\n",
       "      <th>prod_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44.460927</td>\n",
       "      <td>6.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>15.831372</td>\n",
       "      <td>250.632326</td>\n",
       "      <td>46.216444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.897475</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>25.980762</td>\n",
       "      <td>675.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>58.524277</td>\n",
       "      <td>28.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>20.107806</td>\n",
       "      <td>404.323868</td>\n",
       "      <td>49.544407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>21.936792</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>25.980762</td>\n",
       "      <td>675.0</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>50.807634</td>\n",
       "      <td>25.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>18.928483</td>\n",
       "      <td>358.287479</td>\n",
       "      <td>42.368451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>26.104542</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>45.077235</td>\n",
       "      <td>24.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8.947864</td>\n",
       "      <td>80.064275</td>\n",
       "      <td>45.367722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.812140</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>31.819805</td>\n",
       "      <td>1012.5</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>55.632718</td>\n",
       "      <td>25.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>17.811346</td>\n",
       "      <td>317.244039</td>\n",
       "      <td>48.017112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>21.850776</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>137</td>\n",
       "      <td>53.955195</td>\n",
       "      <td>23.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>19.814728</td>\n",
       "      <td>392.623441</td>\n",
       "      <td>57.329167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.657178</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>138</td>\n",
       "      <td>55.753194</td>\n",
       "      <td>23.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>21.557853</td>\n",
       "      <td>464.741016</td>\n",
       "      <td>52.681535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.061244</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>139</td>\n",
       "      <td>46.465132</td>\n",
       "      <td>22.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>16.210828</td>\n",
       "      <td>262.790941</td>\n",
       "      <td>43.477958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.163364</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>140</td>\n",
       "      <td>57.077212</td>\n",
       "      <td>24.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>21.608106</td>\n",
       "      <td>466.910264</td>\n",
       "      <td>53.576627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17.602888</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>141</td>\n",
       "      <td>42.721661</td>\n",
       "      <td>24.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.754629</td>\n",
       "      <td>76.643532</td>\n",
       "      <td>47.296829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.154582</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     jobno   CR1_mean  CR1_min  CR1_max    CR1_std     CR1_var   ER1_mean  \\\n",
       "0        1  44.460927      6.0    245.0  15.831372  250.632326  46.216444   \n",
       "1        2  58.524277     28.0     92.0  20.107806  404.323868  49.544407   \n",
       "2        4  50.807634     25.0     88.0  18.928483  358.287479  42.368451   \n",
       "3        5  45.077235     24.0     56.0   8.947864   80.064275  45.367722   \n",
       "4        6  55.632718     25.0     86.0  17.811346  317.244039  48.017112   \n",
       "..     ...        ...      ...      ...        ...         ...        ...   \n",
       "112    137  53.955195     23.0     86.0  19.814728  392.623441  57.329167   \n",
       "113    138  55.753194     23.0     95.0  21.557853  464.741016  52.681535   \n",
       "114    139  46.465132     22.0     94.0  16.210828  262.790941  43.477958   \n",
       "115    140  57.077212     24.0    157.0  21.608106  466.910264  53.576627   \n",
       "116    141  42.721661     24.0     57.0   8.754629   76.643532  47.296829   \n",
       "\n",
       "     ER1_min  ER1_max    ER1_std  ...  ST1_min  ST1_max  ST1_std  ST1_var  \\\n",
       "0        1.0    100.0  24.897475  ...     70.0     70.0      0.0      0.0   \n",
       "1        1.0    100.0  21.936792  ...     70.0     70.0      0.0      0.0   \n",
       "2        0.0    100.0  26.104542  ...     70.0     70.0      0.0      0.0   \n",
       "3        1.0    100.0  24.812140  ...     70.0     70.0      0.0      0.0   \n",
       "4        1.0    100.0  21.850776  ...     70.0     70.0      0.0      0.0   \n",
       "..       ...      ...        ...  ...      ...      ...      ...      ...   \n",
       "112      0.0    100.0  22.657178  ...     60.0     60.0      0.0      0.0   \n",
       "113      0.0    100.0  18.061244  ...     60.0     60.0      0.0      0.0   \n",
       "114      0.0    100.0  24.163364  ...     60.0     60.0      0.0      0.0   \n",
       "115      0.0    100.0  17.602888  ...     60.0     60.0      0.0      0.0   \n",
       "116      0.0    100.0  24.154582  ...     60.0     60.0      0.0      0.0   \n",
       "\n",
       "     ST2_mean  ST2_min  ST2_max    ST2_std  ST2_var  prod_grade  \n",
       "0        80.0     50.0     95.0  25.980762    675.0           A  \n",
       "1        80.0     50.0     95.0  25.980762    675.0          A-  \n",
       "2        95.0     95.0     95.0   0.000000      0.0          B-  \n",
       "3        72.5     50.0     95.0  31.819805   1012.5          A-  \n",
       "4        95.0     95.0     95.0   0.000000      0.0           A  \n",
       "..        ...      ...      ...        ...      ...         ...  \n",
       "112      95.0     95.0     95.0   0.000000      0.0           A  \n",
       "113      95.0     95.0     95.0   0.000000      0.0           A  \n",
       "114      95.0     95.0     95.0   0.000000      0.0           A  \n",
       "115      95.0     95.0     95.0   0.000000      0.0           A  \n",
       "116      95.0     95.0     95.0   0.000000      0.0           A  \n",
       "\n",
       "[117 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data import\n",
    "train=pd.read_csv(\"G:\\\\내 드라이브\\\\Lab\\code\\\\workplace\\\\Study\\\\DL\\\\TabNet\\\\data\\\\atc\\\\pivot.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe7066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jobno': 117, 'CR1_mean': 116, 'CR1_min': 27, 'CR1_max': 41, 'CR1_std': 116, 'CR1_var': 116, 'ER1_mean': 116, 'ER1_min': 8, 'ER1_max': 8, 'ER1_std': 116, 'ER1_var': 116, 'ST1_mean': 3, 'ST1_min': 3, 'ST1_max': 2, 'ST1_std': 2, 'ST1_var': 2, 'ST2_mean': 4, 'ST2_min': 3, 'ST2_max': 1, 'ST2_std': 4, 'ST2_var': 4, 'prod_grade': 4}\n"
     ]
    }
   ],
   "source": [
    "encoder=LabelEncoder()\n",
    "categorical_dims={}\n",
    "\n",
    "for col in train.columns:\n",
    "    train[col]=encoder.fit_transform(train[col].values)\n",
    "    categorical_dims[col]=train[col].nunique()\n",
    "print(categorical_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68c405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "['jobno', 'CR1_mean', 'CR1_min', 'CR1_max', 'CR1_std', 'CR1_var', 'ER1_mean', 'ER1_min', 'ER1_max', 'ER1_std', 'ER1_var', 'ST1_mean', 'ST1_min', 'ST1_max', 'ST1_std', 'ST1_var', 'ST2_mean', 'ST2_min', 'ST2_max', 'ST2_std', 'ST2_var']\n",
      "[117, 116, 27, 41, 116, 116, 116, 8, 8, 116, 116, 3, 3, 2, 2, 2, 4, 3, 1, 4, 4]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "features=train.columns.tolist()\n",
    "features.remove('prod_grade')\n",
    "print(len(features))\n",
    "print(features)\n",
    "cat_idxs=[]\n",
    "for i,x in enumerate(features):\n",
    "    cat_idxs.append(i)\n",
    "\n",
    "\n",
    "cat_dims=[]\n",
    "for v in categorical_dims.values():\n",
    "    cat_dims.append(v)\n",
    "\n",
    "cat_dims=cat_dims[:-1]\n",
    "print(cat_dims)\n",
    "print(len(cat_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fde2f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "tabnet_params = {\"cat_idxs\":cat_idxs,\n",
    "                 \"cat_dims\":cat_dims,\n",
    "                 \"cat_emb_dim\":1,\n",
    "                 \"optimizer_fn\":torch.optim.Adam,\n",
    "                 \"optimizer_params\":dict(lr=2e-2),\n",
    "                 \"scheduler_params\":{\"step_size\":50, # how to use learning rate scheduler\n",
    "                                 \"gamma\":0.9},\n",
    "                 \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
    "                 \"mask_type\":'entmax' # \"sparsemax\"\n",
    "                }\n",
    "\n",
    "clf = TabNetClassifier(**tabnet_params\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a479d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      3\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "112    0\n",
      "113    0\n",
      "114    0\n",
      "115    0\n",
      "116    0\n",
      "Name: prod_grade, Length: 117, dtype: int32\n",
      "[[ 91  72  13 ...   0   0   0]\n",
      " [ 98  60  14 ...   0   0   0]\n",
      " [ 81  32   9 ...   0   0   0]\n",
      " ...\n",
      " [ 92 115  17 ...   0   0   0]\n",
      " [ 74   6   6 ...   0   0   0]\n",
      " [  3  40  22 ...   0   2   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=train.drop(['prod_grade'],axis=1)\n",
    "Y=train['prod_grade']\n",
    "print(Y)\n",
    "\n",
    "X=X.to_numpy()\n",
    "Y=Y.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.1, shuffle=True, random_state=1004)\n",
    "X_train, X_val, y_train, y_val=train_test_split(X_train,y_train,test_size=0.1, shuffle=True, random_state=1004)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9be3da11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d8ca61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100 if not os.getenv(\"CI\", False) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5050a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.1892  | train_accuracy: 0.32979 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 1  | loss: 1.71763 | train_accuracy: 0.37234 | valid_accuracy: 0.45455 |  0:00:01s\n",
      "epoch 2  | loss: 1.59906 | train_accuracy: 0.32979 | valid_accuracy: 0.45455 |  0:00:01s\n",
      "epoch 3  | loss: 1.41191 | train_accuracy: 0.32979 | valid_accuracy: 0.27273 |  0:00:01s\n",
      "epoch 4  | loss: 1.20379 | train_accuracy: 0.31915 | valid_accuracy: 0.18182 |  0:00:01s\n",
      "epoch 5  | loss: 1.24391 | train_accuracy: 0.37234 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 6  | loss: 1.15698 | train_accuracy: 0.40426 | valid_accuracy: 0.27273 |  0:00:01s\n",
      "epoch 7  | loss: 1.01449 | train_accuracy: 0.45745 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 8  | loss: 0.94755 | train_accuracy: 0.51064 | valid_accuracy: 0.45455 |  0:00:01s\n",
      "epoch 9  | loss: 0.87232 | train_accuracy: 0.44681 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 10 | loss: 0.85156 | train_accuracy: 0.45745 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 11 | loss: 0.8867  | train_accuracy: 0.40426 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 12 | loss: 0.84166 | train_accuracy: 0.3617  | valid_accuracy: 0.27273 |  0:00:02s\n",
      "epoch 13 | loss: 0.68311 | train_accuracy: 0.32979 | valid_accuracy: 0.18182 |  0:00:02s\n",
      "epoch 14 | loss: 0.71325 | train_accuracy: 0.37234 | valid_accuracy: 0.27273 |  0:00:02s\n",
      "epoch 15 | loss: 0.69864 | train_accuracy: 0.37234 | valid_accuracy: 0.27273 |  0:00:02s\n",
      "epoch 16 | loss: 0.95086 | train_accuracy: 0.3617  | valid_accuracy: 0.27273 |  0:00:02s\n",
      "epoch 17 | loss: 0.57556 | train_accuracy: 0.35106 | valid_accuracy: 0.18182 |  0:00:02s\n",
      "epoch 18 | loss: 0.49641 | train_accuracy: 0.31915 | valid_accuracy: 0.18182 |  0:00:02s\n",
      "epoch 19 | loss: 0.48485 | train_accuracy: 0.30851 | valid_accuracy: 0.18182 |  0:00:02s\n",
      "epoch 20 | loss: 0.611   | train_accuracy: 0.30851 | valid_accuracy: 0.18182 |  0:00:02s\n",
      "epoch 21 | loss: 0.71548 | train_accuracy: 0.31915 | valid_accuracy: 0.18182 |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_valid_accuracy = 0.45455\n",
      "Best weights from best epoch are automatically used!\n",
      "epoch 0  | loss: 1.81318 | train_accuracy: 0.3617  | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 1  | loss: 1.47804 | train_accuracy: 0.40426 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 2  | loss: 1.19313 | train_accuracy: 0.39362 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 3  | loss: 1.29921 | train_accuracy: 0.45745 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 4  | loss: 1.28525 | train_accuracy: 0.5     | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 5  | loss: 1.23134 | train_accuracy: 0.5     | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 6  | loss: 0.97259 | train_accuracy: 0.5     | valid_accuracy: 0.54545 |  0:00:00s\n",
      "epoch 7  | loss: 0.93529 | train_accuracy: 0.51064 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 8  | loss: 0.91122 | train_accuracy: 0.58511 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 9  | loss: 1.01095 | train_accuracy: 0.59574 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 10 | loss: 0.87175 | train_accuracy: 0.58511 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 11 | loss: 0.85481 | train_accuracy: 0.52128 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 12 | loss: 0.9802  | train_accuracy: 0.53191 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 13 | loss: 0.66527 | train_accuracy: 0.52128 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 14 | loss: 0.7002  | train_accuracy: 0.52128 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 15 | loss: 0.60754 | train_accuracy: 0.52128 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 16 | loss: 0.95008 | train_accuracy: 0.46809 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 17 | loss: 0.86005 | train_accuracy: 0.41489 | valid_accuracy: 0.27273 |  0:00:00s\n",
      "epoch 18 | loss: 0.69035 | train_accuracy: 0.40426 | valid_accuracy: 0.27273 |  0:00:00s\n",
      "epoch 19 | loss: 0.95426 | train_accuracy: 0.42553 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 20 | loss: 0.64139 | train_accuracy: 0.39362 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 21 | loss: 0.61488 | train_accuracy: 0.37234 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 22 | loss: 0.49796 | train_accuracy: 0.35106 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 23 | loss: 0.5626  | train_accuracy: 0.31915 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 24 | loss: 0.41762 | train_accuracy: 0.30851 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 25 | loss: 0.50791 | train_accuracy: 0.2766  | valid_accuracy: 0.27273 |  0:00:00s\n",
      "epoch 26 | loss: 0.45376 | train_accuracy: 0.29787 | valid_accuracy: 0.27273 |  0:00:00s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_valid_accuracy = 0.54545\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "save_history = []\n",
    "for _ in range(2):\n",
    "    clf.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        eval_name=['train', 'valid'],\n",
    "        eval_metric=['accuracy'],\n",
    "        max_epochs=max_epochs , patience=20,\n",
    "        batch_size=1024, virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        weights=1,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    save_history.append(clf.history[\"valid_accuracy\"])\n",
    "    \n",
    "#assert(np.all(np.array(save_history[0]==np.array(save_history[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e9814c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class TabNetClassifier(TabModel):\\n    def __post_init__(self):\\n        super(TabNetClassifier, self).__post_init__()\\n        self._task = \\'classification\\'\\n        self._default_loss = torch.nn.functional.cross_entropy\\n        self._default_metric = \\'accuracy\\'\\n\\n    def weight_updater(self, weights):\\n        \"\"\"\\n        Updates weights dictionary according to target_mapper.\\n\\n        Parameters\\n        ----------\\n        weights : bool or dict\\n            Given weights for balancing training.\\n\\n        Returns\\n        -------\\n        bool or dict\\n            Same bool if weights are bool, updated dict otherwise.\\n\\n        \"\"\"\\n        if isinstance(weights, int):\\n            return weights\\n        elif isinstance(weights, dict):\\n            return {self.target_mapper[key]: value for key, value in weights.items()}\\n        else:\\n            return weights\\n\\n    def prepare_target(self, y):\\n        return np.vectorize(self.target_mapper.get)(y)\\n\\n    def compute_loss(self, y_pred, y_true):\\n        return self.loss_fn(y_pred, y_true.long())\\n\\n    def update_fit_params(\\n        self,\\n        X_train,\\n        y_train,\\n        eval_set,\\n        weights,\\n    ):\\n        output_dim, train_labels = infer_output_dim(y_train)\\n        for X, y in eval_set:\\n            check_output_dim(train_labels, y)\\n        self.output_dim = output_dim\\n        self._default_metric = (\\'auc\\' if self.output_dim == 2 else \\'accuracy\\')\\n        self.classes_ = train_labels\\n        self.target_mapper = {\\n            class_label: index for index, class_label in enumerate(self.classes_)\\n        }\\n        self.preds_mapper = {\\n            str(index): class_label for index, class_label in enumerate(self.classes_)\\n        }\\n        self.updated_weights = self.weight_updater(weights)\\n\\n    def stack_batches(self, list_y_true, list_y_score):\\n        y_true = np.hstack(list_y_true)\\n        y_score = np.vstack(list_y_score)\\n        y_score = softmax(y_score, axis=1)\\n        return y_true, y_score\\n\\n    def predict_func(self, outputs):\\n        outputs = np.argmax(outputs, axis=1)\\n        return np.vectorize(self.preds_mapper.get)(outputs.astype(str))\\n\\n    def predict_proba(self, X):\\n        \"\"\"\\n        Make predictions for classification on a batch (valid)\\n\\n        Parameters\\n        ----------\\n        X : a :tensor: `torch.Tensor`\\n            Input data\\n\\n        Returns\\n        -------\\n        res : np.ndarray\\n\\n        \"\"\"\\n        self.network.eval()\\n\\n        dataloader = DataLoader(\\n            PredictDataset(X),\\n            batch_size=self.batch_size,\\n            shuffle=False,\\n        )\\n\\n        results = []\\n        for batch_nb, data in enumerate(dataloader):\\n            data = data.to(self.device).float()\\n\\n            output, M_loss = self.network(data)\\n            predictions = torch.nn.Softmax(dim=1)(output).cpu().detach().numpy()\\n            results.append(predictions)\\n        res = np.vstack(results)\\n        return res\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "inspect.getsource(TabNetClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f81825b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_preds = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a816f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.clip(clf.predict(X_test), a_min=0, a_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ee8b2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3706972 , 0.18854319, 0.26932365, 0.17143601],\n",
       "       [0.36162755, 0.2758174 , 0.196757  , 0.16579801],\n",
       "       [0.3504552 , 0.25773442, 0.20714433, 0.18466604],\n",
       "       [0.3329279 , 0.22734943, 0.23135552, 0.20836714],\n",
       "       [0.38584656, 0.28838763, 0.18262425, 0.14314157],\n",
       "       [0.33637583, 0.26669964, 0.21311566, 0.18380883],\n",
       "       [0.50446576, 0.19304134, 0.19928128, 0.10321161],\n",
       "       [0.2969648 , 0.3071926 , 0.19854328, 0.19729929],\n",
       "       [0.14732876, 0.49978295, 0.13377495, 0.21911334],\n",
       "       [0.38320157, 0.27576166, 0.19136848, 0.14966834],\n",
       "       [0.45049116, 0.48952323, 0.03631143, 0.02367421],\n",
       "       [0.44024584, 0.18026043, 0.22523406, 0.15425968]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c8ac2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 3, 0, 3, 1, 3,\n",
       "       0, 0, 2, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d2c5240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 모델 평가 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80        11\n",
      "           1       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.30      0.24      0.27        12\n",
      "weighted avg       0.81      0.67      0.73        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sohyang\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sohyang\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sohyang\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sohyang\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sohyang\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sohyang\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, pred)\n",
    "print(\">> 모델 평가 리포트\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6f9ae60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54,   0,   3,   6,  42,  42,   5,   0,   6,  94,  94,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [ 93, 103,  14,  40, 104, 104,  82,   0,   6,  42,  42,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [ 17,  30,  18,   9,   2,   2,  32,   0,   6,  56,  56,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [ 76,  75,   7,  11,  77,  77,  65,   0,   6,  90,  90,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [ 79,  58,  10,  21,  53,  53,  72,   0,   6,  60,  60,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [ 88,  79,  11,  19,  80,  80,  51,   0,   6,  53,  53,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [ 38,   2,   7,  18,  44,  44,  11,   0,   6, 100, 100,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [ 78,  23,   9,   7,  19,  19,  61,   1,   6,  27,  27,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [ 94,  16,  12,   9,  11,  11,  24,   1,   6,  73,  73,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [  8,  92,  19,  19,  83,  83,  86,   4,   6,  25,  25,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [ 40,  54,  12,  12,  32,  32, 101,   1,   6,  18,  18,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [ 46,  71,  24,  26, 105, 105, 100,   2,   6,  30,  30,   1,   1,\n",
       "          0,   0,   0,   3,   2,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed9780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d5421a455d8aa870f44bbd33dd29bee7ba5cffdfaaf8db002da4ff8e6d6e14f"
  },
  "kernelspec": {
   "display_name": "Env5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
