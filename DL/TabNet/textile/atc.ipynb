{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42a9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "import os\n",
    "import wget\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d279429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     jobno   CR1_mean  CR1_min  CR1_max    CR1_std     CR1_var   ER1_mean  \\\n",
      "0        1  44.460927      6.0    245.0  15.831372  250.632326  46.216444   \n",
      "1        2  58.524277     28.0     92.0  20.107806  404.323868  49.544407   \n",
      "2        4  50.807634     25.0     88.0  18.928483  358.287479  42.368451   \n",
      "3        5  45.077235     24.0     56.0   8.947864   80.064275  45.367722   \n",
      "4        6  55.632718     25.0     86.0  17.811346  317.244039  48.017112   \n",
      "..     ...        ...      ...      ...        ...         ...        ...   \n",
      "112    137  53.955195     23.0     86.0  19.814728  392.623441  57.329167   \n",
      "113    138  55.753194     23.0     95.0  21.557853  464.741016  52.681535   \n",
      "114    139  46.465132     22.0     94.0  16.210828  262.790941  43.477958   \n",
      "115    140  57.077212     24.0    157.0  21.608106  466.910264  53.576627   \n",
      "116    141  42.721661     24.0     57.0   8.754629   76.643532  47.296829   \n",
      "\n",
      "     ER1_min  ER1_max    ER1_std  ...  ST1_min  ST1_max  ST1_std  ST1_var  \\\n",
      "0        1.0    100.0  24.897475  ...     70.0     70.0      0.0      0.0   \n",
      "1        1.0    100.0  21.936792  ...     70.0     70.0      0.0      0.0   \n",
      "2        0.0    100.0  26.104542  ...     70.0     70.0      0.0      0.0   \n",
      "3        1.0    100.0  24.812140  ...     70.0     70.0      0.0      0.0   \n",
      "4        1.0    100.0  21.850776  ...     70.0     70.0      0.0      0.0   \n",
      "..       ...      ...        ...  ...      ...      ...      ...      ...   \n",
      "112      0.0    100.0  22.657178  ...     60.0     60.0      0.0      0.0   \n",
      "113      0.0    100.0  18.061244  ...     60.0     60.0      0.0      0.0   \n",
      "114      0.0    100.0  24.163364  ...     60.0     60.0      0.0      0.0   \n",
      "115      0.0    100.0  17.602888  ...     60.0     60.0      0.0      0.0   \n",
      "116      0.0    100.0  24.154582  ...     60.0     60.0      0.0      0.0   \n",
      "\n",
      "     ST2_mean  ST2_min  ST2_max    ST2_std  ST2_var  prod_grade  \n",
      "0        80.0     50.0     95.0  25.980762    675.0           A  \n",
      "1        80.0     50.0     95.0  25.980762    675.0          A-  \n",
      "2        95.0     95.0     95.0   0.000000      0.0          B-  \n",
      "3        72.5     50.0     95.0  31.819805   1012.5          A-  \n",
      "4        95.0     95.0     95.0   0.000000      0.0           A  \n",
      "..        ...      ...      ...        ...      ...         ...  \n",
      "112      95.0     95.0     95.0   0.000000      0.0           A  \n",
      "113      95.0     95.0     95.0   0.000000      0.0           A  \n",
      "114      95.0     95.0     95.0   0.000000      0.0           A  \n",
      "115      95.0     95.0     95.0   0.000000      0.0           A  \n",
      "116      95.0     95.0     95.0   0.000000      0.0           A  \n",
      "\n",
      "[117 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#data import\n",
    "train=pd.read_csv(\"G:\\\\내 드라이브\\\\Lab\\code\\\\workplace\\\\Study\\\\DL\\\\TabNet\\\\data\\\\atc\\\\pivot.csv\")\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe7066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jobno': 117, 'CR1_mean': 116, 'CR1_min': 27, 'CR1_max': 41, 'CR1_std': 116, 'CR1_var': 116, 'ER1_mean': 116, 'ER1_min': 8, 'ER1_max': 8, 'ER1_std': 116, 'ER1_var': 116, 'ST1_mean': 3, 'ST1_min': 3, 'ST1_max': 2, 'ST1_std': 2, 'ST1_var': 2, 'ST2_mean': 4, 'ST2_min': 3, 'ST2_max': 1, 'ST2_std': 4, 'ST2_var': 4, 'prod_grade': 4}\n"
     ]
    }
   ],
   "source": [
    "encoder=LabelEncoder()\n",
    "categorical_dims={}\n",
    "\n",
    "for col in train.columns:\n",
    "    train[col]=encoder.fit_transform(train[col].values)\n",
    "    categorical_dims[col]=train[col].nunique()\n",
    "print(categorical_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68c405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "['jobno', 'CR1_mean', 'CR1_min', 'CR1_max', 'CR1_std', 'CR1_var', 'ER1_mean', 'ER1_min', 'ER1_max', 'ER1_std', 'ER1_var', 'ST1_mean', 'ST1_min', 'ST1_max', 'ST1_std', 'ST1_var', 'ST2_mean', 'ST2_min', 'ST2_max', 'ST2_std', 'ST2_var']\n",
      "[117, 116, 27, 41, 116, 116, 116, 8, 8, 116, 116, 3, 3, 2, 2, 2, 4, 3, 1, 4, 4]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "features=train.columns.tolist()\n",
    "features.remove('prod_grade')\n",
    "print(len(features))\n",
    "print(features)\n",
    "cat_idxs=[]\n",
    "for i,x in enumerate(features):\n",
    "    cat_idxs.append(i)\n",
    "\n",
    "\n",
    "cat_dims=[]\n",
    "for v in categorical_dims.values():\n",
    "    cat_dims.append(v)\n",
    "\n",
    "cat_dims=cat_dims[:-1]\n",
    "print(cat_dims)\n",
    "print(len(cat_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fde2f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "tabnet_params = {\"cat_idxs\":cat_idxs,\n",
    "                 \"cat_dims\":cat_dims,\n",
    "                 \"cat_emb_dim\":1,\n",
    "                 \"optimizer_fn\":torch.optim.Adam,\n",
    "                 \"optimizer_params\":dict(lr=2e-2),\n",
    "                 \"scheduler_params\":{\"step_size\":50, # how to use learning rate scheduler\n",
    "                                 \"gamma\":0.9},\n",
    "                 \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
    "                 \"mask_type\":'entmax' # \"sparsemax\"\n",
    "                }\n",
    "\n",
    "clf = TabNetClassifier(**tabnet_params\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a479d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      3\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "112    0\n",
      "113    0\n",
      "114    0\n",
      "115    0\n",
      "116    0\n",
      "Name: prod_grade, Length: 117, dtype: int32\n",
      "[[ 91  72  13 ...   0   0   0]\n",
      " [ 98  60  14 ...   0   0   0]\n",
      " [ 81  32   9 ...   0   0   0]\n",
      " ...\n",
      " [ 92 115  17 ...   0   0   0]\n",
      " [ 74   6   6 ...   0   0   0]\n",
      " [  3  40  22 ...   0   2   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=train.drop(['prod_grade'],axis=1)\n",
    "Y=train['prod_grade']\n",
    "print(Y)\n",
    "\n",
    "X=X.to_numpy()\n",
    "Y=Y.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.1, shuffle=True, random_state=1004)\n",
    "X_train, X_val, y_train, y_val=train_test_split(X_train,y_train,test_size=0.1, shuffle=True, random_state=1004)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8ca61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100 if not os.getenv(\"CI\", False) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5050a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.1892  | train_accuracy: 0.32979 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 1  | loss: 1.71763 | train_accuracy: 0.37234 | valid_accuracy: 0.45455 |  0:00:01s\n",
      "epoch 2  | loss: 1.59906 | train_accuracy: 0.32979 | valid_accuracy: 0.45455 |  0:00:01s\n",
      "epoch 3  | loss: 1.41191 | train_accuracy: 0.32979 | valid_accuracy: 0.27273 |  0:00:01s\n",
      "epoch 4  | loss: 1.20379 | train_accuracy: 0.31915 | valid_accuracy: 0.18182 |  0:00:01s\n",
      "epoch 5  | loss: 1.24391 | train_accuracy: 0.37234 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 6  | loss: 1.15698 | train_accuracy: 0.40426 | valid_accuracy: 0.27273 |  0:00:01s\n",
      "epoch 7  | loss: 1.01449 | train_accuracy: 0.45745 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 8  | loss: 0.94755 | train_accuracy: 0.51064 | valid_accuracy: 0.45455 |  0:00:01s\n",
      "epoch 9  | loss: 0.87232 | train_accuracy: 0.44681 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 10 | loss: 0.85156 | train_accuracy: 0.45745 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 11 | loss: 0.8867  | train_accuracy: 0.40426 | valid_accuracy: 0.36364 |  0:00:01s\n",
      "epoch 12 | loss: 0.84166 | train_accuracy: 0.3617  | valid_accuracy: 0.27273 |  0:00:01s\n",
      "epoch 13 | loss: 0.68311 | train_accuracy: 0.32979 | valid_accuracy: 0.18182 |  0:00:01s\n",
      "epoch 14 | loss: 0.71325 | train_accuracy: 0.37234 | valid_accuracy: 0.27273 |  0:00:01s\n",
      "epoch 15 | loss: 0.69864 | train_accuracy: 0.37234 | valid_accuracy: 0.27273 |  0:00:01s\n",
      "epoch 16 | loss: 0.95086 | train_accuracy: 0.3617  | valid_accuracy: 0.27273 |  0:00:01s\n",
      "epoch 17 | loss: 0.57556 | train_accuracy: 0.35106 | valid_accuracy: 0.18182 |  0:00:02s\n",
      "epoch 18 | loss: 0.49641 | train_accuracy: 0.31915 | valid_accuracy: 0.18182 |  0:00:02s\n",
      "epoch 19 | loss: 0.48485 | train_accuracy: 0.30851 | valid_accuracy: 0.18182 |  0:00:02s\n",
      "epoch 20 | loss: 0.611   | train_accuracy: 0.30851 | valid_accuracy: 0.18182 |  0:00:02s\n",
      "epoch 21 | loss: 0.71548 | train_accuracy: 0.31915 | valid_accuracy: 0.18182 |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_valid_accuracy = 0.45455\n",
      "Best weights from best epoch are automatically used!\n",
      "epoch 0  | loss: 1.81318 | train_accuracy: 0.3617  | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 1  | loss: 1.47804 | train_accuracy: 0.40426 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 2  | loss: 1.19313 | train_accuracy: 0.39362 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 3  | loss: 1.29921 | train_accuracy: 0.45745 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 4  | loss: 1.28525 | train_accuracy: 0.5     | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 5  | loss: 1.23134 | train_accuracy: 0.5     | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 6  | loss: 0.97259 | train_accuracy: 0.5     | valid_accuracy: 0.54545 |  0:00:00s\n",
      "epoch 7  | loss: 0.93529 | train_accuracy: 0.51064 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 8  | loss: 0.91122 | train_accuracy: 0.58511 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 9  | loss: 1.01095 | train_accuracy: 0.59574 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 10 | loss: 0.87175 | train_accuracy: 0.58511 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 11 | loss: 0.85481 | train_accuracy: 0.52128 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 12 | loss: 0.9802  | train_accuracy: 0.53191 | valid_accuracy: 0.45455 |  0:00:00s\n",
      "epoch 13 | loss: 0.66527 | train_accuracy: 0.52128 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 14 | loss: 0.7002  | train_accuracy: 0.52128 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 15 | loss: 0.60754 | train_accuracy: 0.52128 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 16 | loss: 0.95008 | train_accuracy: 0.46809 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 17 | loss: 0.86005 | train_accuracy: 0.41489 | valid_accuracy: 0.27273 |  0:00:00s\n",
      "epoch 18 | loss: 0.69035 | train_accuracy: 0.40426 | valid_accuracy: 0.27273 |  0:00:00s\n",
      "epoch 19 | loss: 0.95426 | train_accuracy: 0.42553 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 20 | loss: 0.64139 | train_accuracy: 0.39362 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 21 | loss: 0.61488 | train_accuracy: 0.37234 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 22 | loss: 0.49796 | train_accuracy: 0.35106 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 23 | loss: 0.5626  | train_accuracy: 0.31915 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 24 | loss: 0.41762 | train_accuracy: 0.30851 | valid_accuracy: 0.36364 |  0:00:00s\n",
      "epoch 25 | loss: 0.50791 | train_accuracy: 0.2766  | valid_accuracy: 0.27273 |  0:00:00s\n",
      "epoch 26 | loss: 0.45376 | train_accuracy: 0.29787 | valid_accuracy: 0.27273 |  0:00:00s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_valid_accuracy = 0.54545\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "save_history = []\n",
    "for _ in range(2):\n",
    "    clf.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        eval_name=['train', 'valid'],\n",
    "        eval_metric=['accuracy'],\n",
    "        max_epochs=max_epochs , patience=20,\n",
    "        batch_size=1024, virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        weights=1,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    save_history.append(clf.history[\"valid_accuracy\"])\n",
    "    \n",
    "#assert(np.all(np.array(save_history[0]==np.array(save_history[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9814c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class TabNetClassifier(TabModel):\\n    def __post_init__(self):\\n        super(TabNetClassifier, self).__post_init__()\\n        self._task = \\'classification\\'\\n        self._default_loss = torch.nn.functional.cross_entropy\\n        self._default_metric = \\'accuracy\\'\\n\\n    def weight_updater(self, weights):\\n        \"\"\"\\n        Updates weights dictionary according to target_mapper.\\n\\n        Parameters\\n        ----------\\n        weights : bool or dict\\n            Given weights for balancing training.\\n\\n        Returns\\n        -------\\n        bool or dict\\n            Same bool if weights are bool, updated dict otherwise.\\n\\n        \"\"\"\\n        if isinstance(weights, int):\\n            return weights\\n        elif isinstance(weights, dict):\\n            return {self.target_mapper[key]: value for key, value in weights.items()}\\n        else:\\n            return weights\\n\\n    def prepare_target(self, y):\\n        return np.vectorize(self.target_mapper.get)(y)\\n\\n    def compute_loss(self, y_pred, y_true):\\n        return self.loss_fn(y_pred, y_true.long())\\n\\n    def update_fit_params(\\n        self,\\n        X_train,\\n        y_train,\\n        eval_set,\\n        weights,\\n    ):\\n        output_dim, train_labels = infer_output_dim(y_train)\\n        for X, y in eval_set:\\n            check_output_dim(train_labels, y)\\n        self.output_dim = output_dim\\n        self._default_metric = (\\'auc\\' if self.output_dim == 2 else \\'accuracy\\')\\n        self.classes_ = train_labels\\n        self.target_mapper = {\\n            class_label: index for index, class_label in enumerate(self.classes_)\\n        }\\n        self.preds_mapper = {\\n            str(index): class_label for index, class_label in enumerate(self.classes_)\\n        }\\n        self.updated_weights = self.weight_updater(weights)\\n\\n    def stack_batches(self, list_y_true, list_y_score):\\n        y_true = np.hstack(list_y_true)\\n        y_score = np.vstack(list_y_score)\\n        y_score = softmax(y_score, axis=1)\\n        return y_true, y_score\\n\\n    def predict_func(self, outputs):\\n        outputs = np.argmax(outputs, axis=1)\\n        return np.vectorize(self.preds_mapper.get)(outputs.astype(str))\\n\\n    def predict_proba(self, X):\\n        \"\"\"\\n        Make predictions for classification on a batch (valid)\\n\\n        Parameters\\n        ----------\\n        X : a :tensor: `torch.Tensor`\\n            Input data\\n\\n        Returns\\n        -------\\n        res : np.ndarray\\n\\n        \"\"\"\\n        self.network.eval()\\n\\n        dataloader = DataLoader(\\n            PredictDataset(X),\\n            batch_size=self.batch_size,\\n            shuffle=False,\\n        )\\n\\n        results = []\\n        for batch_nb, data in enumerate(dataloader):\\n            data = data.to(self.device).float()\\n\\n            output, M_loss = self.network(data)\\n            predictions = torch.nn.Softmax(dim=1)(output).cpu().detach().numpy()\\n            results.append(predictions)\\n        res = np.vstack(results)\\n        return res\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "inspect.getsource(TabNetClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81825b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d5421a455d8aa870f44bbd33dd29bee7ba5cffdfaaf8db002da4ff8e6d6e14f"
  },
  "kernelspec": {
   "display_name": "Env5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
